{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I pulled and cleaned a comprehensive dataset of colleges from this governmental database:\n",
    "    \n",
    "https://collegescorecard.ed.gov/data/\n",
    "\n",
    "Let's read this dataset in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6740, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ownership</th>\n",
       "      <th>ope6_id</th>\n",
       "      <th>state</th>\n",
       "      <th>size</th>\n",
       "      <th>accreditor</th>\n",
       "      <th>retention</th>\n",
       "      <th>branches</th>\n",
       "      <th>online_only</th>\n",
       "      <th>religious_affil</th>\n",
       "      <th>...</th>\n",
       "      <th>fafsa_sent</th>\n",
       "      <th>7_yr_repayment_completion</th>\n",
       "      <th>5_year_declining_balance</th>\n",
       "      <th>relig_y_n</th>\n",
       "      <th>accred_y_n</th>\n",
       "      <th>retention_listed_y_n</th>\n",
       "      <th>fac_salary_listed_y_n</th>\n",
       "      <th>7_yr_repayment_completion_y_n</th>\n",
       "      <th>5_year_declining_balance_y_n</th>\n",
       "      <th>for_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alaska Bible College</td>\n",
       "      <td>2</td>\n",
       "      <td>8843</td>\n",
       "      <td>AK</td>\n",
       "      <td>27</td>\n",
       "      <td>Association for Bibical Higher Educaiton</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463652</td>\n",
       "      <td>0.699542</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska Christian College</td>\n",
       "      <td>2</td>\n",
       "      <td>41386</td>\n",
       "      <td>AK</td>\n",
       "      <td>68</td>\n",
       "      <td>Association for Bibical Higher Educaiton</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463652</td>\n",
       "      <td>0.699542</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ilisagvik College</td>\n",
       "      <td>1</td>\n",
       "      <td>34613</td>\n",
       "      <td>AK</td>\n",
       "      <td>109</td>\n",
       "      <td>Northwest Commission on Colleges and Universities</td>\n",
       "      <td>0.809500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463652</td>\n",
       "      <td>0.699542</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charter College-Anchorage</td>\n",
       "      <td>3</td>\n",
       "      <td>25769</td>\n",
       "      <td>AK</td>\n",
       "      <td>3256</td>\n",
       "      <td>Accrediting Council for Independent Colleges a...</td>\n",
       "      <td>0.703723</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310288</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.417949</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska Career College</td>\n",
       "      <td>3</td>\n",
       "      <td>25410</td>\n",
       "      <td>AK</td>\n",
       "      <td>479</td>\n",
       "      <td>Accrediting Commission of Career Schools and C...</td>\n",
       "      <td>0.794100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.556430</td>\n",
       "      <td>0.462520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  ownership  ope6_id state  size  \\\n",
       "0       Alaska Bible College          2     8843    AK    27   \n",
       "1   Alaska Christian College          2    41386    AK    68   \n",
       "2          Ilisagvik College          1    34613    AK   109   \n",
       "3  Charter College-Anchorage          3    25769    AK  3256   \n",
       "4      Alaska Career College          3    25410    AK   479   \n",
       "\n",
       "                                          accreditor  retention  branches  \\\n",
       "0           Association for Bibical Higher Educaiton   0.333300         1   \n",
       "1           Association for Bibical Higher Educaiton   0.473700         1   \n",
       "2  Northwest Commission on Colleges and Universities   0.809500         1   \n",
       "3  Accrediting Council for Independent Colleges a...   0.703723         1   \n",
       "4  Accrediting Commission of Career Schools and C...   0.794100         1   \n",
       "\n",
       "   online_only  religious_affil  ...  fafsa_sent  7_yr_repayment_completion  \\\n",
       "0            0             88.0  ...    0.463652                   0.699542   \n",
       "1            0             37.0  ...    0.463652                   0.699542   \n",
       "2            0             -2.0  ...    0.463652                   0.699542   \n",
       "3            0             -2.0  ...    0.310288                   0.725806   \n",
       "4            0             -2.0  ...    0.254237                   0.556430   \n",
       "\n",
       "   5_year_declining_balance  relig_y_n  accred_y_n  retention_listed_y_n  \\\n",
       "0                  0.496850          1           1                     1   \n",
       "1                  0.496850          1           1                     1   \n",
       "2                  0.496850          0           1                     1   \n",
       "3                  0.417949          0           1                     0   \n",
       "4                  0.462520          0           1                     1   \n",
       "\n",
       "   fac_salary_listed_y_n  7_yr_repayment_completion_y_n  \\\n",
       "0                      1                              0   \n",
       "1                      1                              0   \n",
       "2                      1                              0   \n",
       "3                      1                              1   \n",
       "4                      1                              1   \n",
       "\n",
       "   5_year_declining_balance_y_n  for_profit  \n",
       "0                             0           0  \n",
       "1                             0           0  \n",
       "2                             0           0  \n",
       "3                             1           1  \n",
       "4                             1           1  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/schools.csv', index_col = 0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use classification algorithms to try to predict for-profit or non-profit status. \n",
    "\n",
    "Some of the categories aren't applicable to what we want to do so let's consider the following columns only:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>retention</th>\n",
       "      <th>branches</th>\n",
       "      <th>online_only</th>\n",
       "      <th>under_investigation</th>\n",
       "      <th>most_common_degree</th>\n",
       "      <th>highest_degree</th>\n",
       "      <th>faculty_salary</th>\n",
       "      <th>instructional_expenditure_per_fte</th>\n",
       "      <th>tuition_revenue_per_fte</th>\n",
       "      <th>...</th>\n",
       "      <th>fafsa_sent</th>\n",
       "      <th>7_yr_repayment_completion</th>\n",
       "      <th>5_year_declining_balance</th>\n",
       "      <th>relig_y_n</th>\n",
       "      <th>accred_y_n</th>\n",
       "      <th>retention_listed_y_n</th>\n",
       "      <th>fac_salary_listed_y_n</th>\n",
       "      <th>7_yr_repayment_completion_y_n</th>\n",
       "      <th>5_year_declining_balance_y_n</th>\n",
       "      <th>for_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2201</td>\n",
       "      <td>9585</td>\n",
       "      <td>8132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463652</td>\n",
       "      <td>0.699542</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5554</td>\n",
       "      <td>18174</td>\n",
       "      <td>12989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463652</td>\n",
       "      <td>0.699542</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>0.809500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6054</td>\n",
       "      <td>38265</td>\n",
       "      <td>3587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463652</td>\n",
       "      <td>0.699542</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3256</td>\n",
       "      <td>0.703723</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4004</td>\n",
       "      <td>2617</td>\n",
       "      <td>8755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310288</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.417949</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>479</td>\n",
       "      <td>0.794100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3861</td>\n",
       "      <td>4178</td>\n",
       "      <td>11905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.556430</td>\n",
       "      <td>0.462520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   size  retention  branches  online_only  under_investigation  \\\n",
       "0    27   0.333300         1            0                    0   \n",
       "1    68   0.473700         1            0                    0   \n",
       "2   109   0.809500         1            0                    0   \n",
       "3  3256   0.703723         1            0                    0   \n",
       "4   479   0.794100         1            0                    0   \n",
       "\n",
       "   most_common_degree  highest_degree  faculty_salary  \\\n",
       "0                   3               3            2201   \n",
       "1                   1               2            5554   \n",
       "2                   1               2            6054   \n",
       "3                   1               3            4004   \n",
       "4                   1               2            3861   \n",
       "\n",
       "   instructional_expenditure_per_fte  tuition_revenue_per_fte  ...  \\\n",
       "0                               9585                     8132  ...   \n",
       "1                              18174                    12989  ...   \n",
       "2                              38265                     3587  ...   \n",
       "3                               2617                     8755  ...   \n",
       "4                               4178                    11905  ...   \n",
       "\n",
       "   fafsa_sent  7_yr_repayment_completion  5_year_declining_balance  relig_y_n  \\\n",
       "0    0.463652                   0.699542                  0.496850          1   \n",
       "1    0.463652                   0.699542                  0.496850          1   \n",
       "2    0.463652                   0.699542                  0.496850          0   \n",
       "3    0.310288                   0.725806                  0.417949          0   \n",
       "4    0.254237                   0.556430                  0.462520          0   \n",
       "\n",
       "   accred_y_n  retention_listed_y_n  fac_salary_listed_y_n  \\\n",
       "0           1                     1                      1   \n",
       "1           1                     1                      1   \n",
       "2           1                     1                      1   \n",
       "3           1                     0                      1   \n",
       "4           1                     1                      1   \n",
       "\n",
       "   7_yr_repayment_completion_y_n  5_year_declining_balance_y_n  for_profit  \n",
       "0                              0                             0           0  \n",
       "1                              0                             0           0  \n",
       "2                              0                             0           0  \n",
       "3                              1                             1           1  \n",
       "4                              1                             1           1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['size','retention','branches', 'online_only', 'under_investigation', 'most_common_degree', 'highest_degree',\n",
    "       'faculty_salary', 'instructional_expenditure_per_fte',\n",
    "       'tuition_revenue_per_fte', 'part_time_share',\n",
    "       'age_entry', 'percent_dependent', 'first_generation', 'percent_black',\n",
    "        'avg_family_income','ind_low_income', 'dep_low_income', 'loan_principal',\n",
    "       'federal_loan_rate', 'students_with_any_loans',\n",
    "       'pell_grant_debt', 'percent_pell_grant',\n",
    "       'fafsa_sent', '7_yr_repayment_completion', '5_year_declining_balance',\n",
    "       'relig_y_n', 'accred_y_n', 'retention_listed_y_n',\n",
    "       'fac_salary_listed_y_n', '7_yr_repayment_completion_y_n',\n",
    "       '5_year_declining_balance_y_n', 'for_profit']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first use a method called [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html) to see which features have the most statistically significant relationships with profit status. The **lower** the p value, the **more** statistically significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2-value feature\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.0, 'avg_family_income'),\n",
       " (0.0, 'branches'),\n",
       " (0.0, 'faculty_salary'),\n",
       " (0.0, 'instructional_expenditure_per_fte'),\n",
       " (0.0, 'loan_principal'),\n",
       " (0.0, 'pell_grant_debt'),\n",
       " (0.0, 'size'),\n",
       " (0.0, 'tuition_revenue_per_fte'),\n",
       " (5.339096890496358e-283, 'highest_degree'),\n",
       " (2.3550018048916394e-222, 'most_common_degree'),\n",
       " (5.4025502611485345e-149, 'fac_salary_listed_y_n'),\n",
       " (8.240679129762035e-148, 'relig_y_n'),\n",
       " (5.293172158552389e-143, 'age_entry'),\n",
       " (1.4125160311604572e-48, 'percent_dependent'),\n",
       " (1.429381130658807e-24, '5_year_declining_balance'),\n",
       " (1.3527931483014932e-21, 'federal_loan_rate'),\n",
       " (6.095800240149601e-17, 'percent_black'),\n",
       " (3.249757484508949e-15, 'fafsa_sent'),\n",
       " (2.3099399670292976e-10, '7_yr_repayment_completion'),\n",
       " (5.332261659651546e-09, 'first_generation'),\n",
       " (1.4079344574521532e-08, 'part_time_share'),\n",
       " (1.51637032044754e-08, 'dep_low_income'),\n",
       " (5.389960032435694e-08, 'percent_pell_grant'),\n",
       " (2.9423628117769607e-06, 'students_with_any_loans'),\n",
       " (9.035892891499908e-06, 'under_investigation'),\n",
       " (0.006314439338573356, 'retention_listed_y_n'),\n",
       " (0.012536378966747178, 'online_only'),\n",
       " (0.01746153785302311, 'ind_low_income'),\n",
       " (0.5021649291685133, '5_year_declining_balance_y_n'),\n",
       " (0.6158853388832327, 'retention'),\n",
       " (0.8250416943743915, 'accred_y_n'),\n",
       " (0.9230148052834302, '7_yr_repayment_completion_y_n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = X.pop('for_profit')\n",
    "\n",
    "X_new = SelectKBest(chi2, k=2).fit(X, y)\n",
    "\n",
    "features = []\n",
    "for i, column in enumerate(X.columns):\n",
    "    features.append((X_new.pvalues_[i], column))\n",
    "features.sort()\n",
    "print('chi2-value', 'feature')\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Based on the info above, what was intuitive? What was surprising? How big (or small) of an effect does accredition have on for-profit status? What might be some guesses as to why this is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Do a test/train split and give the testing accuracy error for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8981206726013847"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=.30, random_state=4444)\n",
    "\n",
    "model = LogisticRegression(multi_class = \"auto\", solver = 'lbfgs', max_iter=10000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Find the optimal number of nearest neighbors for KNN using grid search and then give the test accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8936696340257171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=.30, random_state=4444)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 9)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Run a classification report and describe in detail what the terms mean in the context of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['              precision    recall  f1-score   support',\n",
       " '',\n",
       " '           0       0.91      0.90      0.91      1144',\n",
       " '           1       0.87      0.89      0.88       878',\n",
       " '',\n",
       " '   micro avg       0.89      0.89      0.89      2022',\n",
       " '   macro avg       0.89      0.89      0.89      2022',\n",
       " 'weighted avg       0.89      0.89      0.89      2022',\n",
       " '']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, model.predict(X_test)).split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Print a confusion matrix and describe what it means in your context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1027,  117],\n",
       "       [  98,  780]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Make a comparative ROC plot of the naive bayes, logistic, gradient boosting, and KNN classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier(X,y,estimator, best_param, fig, ax):\n",
    "    \n",
    "    pipeline = [('scaler', StandardScaler())]\n",
    "    \n",
    "    if estimator == 'logistic':\n",
    "        pipeline.append( ('estimator',  LogisticRegressionCV(Cs=10, cv=5, random_state=1)))\n",
    "    \n",
    "    elif estimator == 'naive_bayes':\n",
    "        pipeline.append(('estimator',  naive_bayes.GaussianNB()))\n",
    "    \n",
    "    elif estimator == 'k_nearest_neighbors':\n",
    "        pipeline.append(('estimator',  KNeighborsClassifier(n_neighbors = 9)))\n",
    "    elif estimator == 'decision_tree':\n",
    "        pipeline.append(('estimator', DecisionTreeClassifier()))            \n",
    "    elif estimator == 'SVM':\n",
    "        pipeline.append(('estimator', svm.SVC(kernel='rbf', probability = True))) #other kernel options 'rbf', 'poly', 'sigmoid'               \n",
    "    elif estimator == 'random_forest':        \n",
    "        pipeline.append(('estimator', RandomForestClassifier(n_estimators = 300)))\n",
    "    elif estimator == 'gradient_boosting':\n",
    "        pipeline.append(('estimator', GradientBoostingClassifier(n_estimators = 300)))\n",
    "        \n",
    "    elif estimator == 'extreme_gb':\n",
    "        pipeline.append(('estimator', XGBClassifier(n_estimators = 300, learning_rate = 0.1)  ))\n",
    "    \n",
    "    elif estimator == 'neural_MLP':\n",
    "        pipeline.append(('estimator', MLPClassifier(\n",
    "        hidden_layer_sizes=(100,),\n",
    "        solver='adam',\n",
    "        verbose=False,\n",
    "        activation='tanh',\n",
    "        learning_rate='adaptive',\n",
    "        early_stopping=False,\n",
    "        max_iter=200,\n",
    "        batch_size=32)))\n",
    "    \n",
    "    else:\n",
    "        print('dont know that estimator')\n",
    "        return None    \n",
    "                        \n",
    "    pipeline = Pipeline(pipeline)\n",
    "                        \n",
    "    #stuff to save                \n",
    "    acc_test=[]\n",
    "    roc_auc= []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    neighbors=[]\n",
    "     \n",
    "        \n",
    "    y_test_score = 0\n",
    "    max_score = 0\n",
    "    \n",
    "    saved_X_test = []\n",
    "    saved_X_train = []\n",
    "    saved_y_test = []\n",
    "    saved_y_train = []\n",
    "    saved_y_proba = []\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle = True)\n",
    "    kf.get_n_splits(X)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "                            \n",
    "        y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "        y_pred = pipeline.predict(X_test)            \n",
    "        \n",
    "        y_test_score = accuracy_score(y_test, y_pred)        \n",
    "        acc_test.append(y_test_score)\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        roc_auc.append(roc_auc_score(y_test, y_proba))\n",
    "\n",
    "        \n",
    "        if y_test_score > max_score:\n",
    "            max_score = y_test_score\n",
    "            saved_X_test = X_test\n",
    "            saved_X_train = X_train\n",
    "            saved_y_test = y_test\n",
    "            saved_y_train = y_train\n",
    "            saved_y_proba = y_proba\n",
    "            saved_pipeline = pipeline.fit(X_train, y_train)\n",
    "            saved_roc_score = roc_auc_score(y_test, y_proba)\n",
    "            \n",
    "            if estimator == 'logistic':\n",
    "                saved_coef = pipeline.steps[-1][1].coef_             \n",
    "    \n",
    "    x,y,z = roc_curve(y_test, y_proba)    \n",
    "    label = '%s, %.1f%%' % (estimator, 100*roc_auc_score(y_test, y_proba) )\n",
    "    fig.suptitle('ROC CURVES', fontweight='bold');\n",
    "    ax.plot([0, 1], [0, 1], color='k', linestyle='--', linewidth=.4);\n",
    "    ax.plot(x,y, label=label);\n",
    "    ax.axis('equal');\n",
    "    ax.set(xlim=[-.02, 1.02], ylim=[-.02, 1.02]);\n",
    "    ax.legend(loc='best');\n",
    "    ax.grid(True);\n",
    "    \n",
    "    \n",
    "    print('best classification report')\n",
    "    print(classification_report(saved_y_test, saved_pipeline.predict(saved_X_test)))\n",
    "#    plot_confusion_matrix(confusion_matrix(saved_y_test, saved_pipeline.predict(saved_X_test)))\n",
    "    \n",
    "\n",
    "    print('av_roc_auc', np.mean(roc_auc))  \n",
    "    print('av_acc_test', np.mean(acc_test))\n",
    "    print('av_precision', np.mean(precision))\n",
    "    print('av_recall', np.mean(recall))\n",
    "\n",
    "        \n",
    "    if estimator == 'logistic':\n",
    "        return np.mean(acc_test), np.mean(roc_auc), np.mean(precision), np.mean(recall), saved_coef, fig, ax                \n",
    "    else:\n",
    "        return np.mean(acc_test), np.mean(roc_auc), np.mean(precision), np.mean(recall), None, fig, ax\n",
    "    \n",
    "#make a comparative ROC plot of all of the estimators\n",
    "\n",
    "models = ['naive_bayes', 'logistic', 'decision_tree', 'k_nearest_neighbors', 'SVM','neural_MLP', 'random_forest', 'gradient_boosting']\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "for model in models:\n",
    "    my_classifier(X,y, model,_, fig, ax)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "7.Using the logarithm regression model, plot a decision boundary between instructional_expenditure_per_fte and 5_year_declining_balance. Does it appear that for-profit status has a clear boundary based on these predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot decision boundaries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature1 = 'instructional_expenditure_per_fte'\n",
    "feature2 = '5_year_declining_balance'\n",
    "X = df[['5_year_declining_balance', 'instructional_expenditure_per_fte', 'tuition_revenue_per_fte']]\n",
    "y = df['for_profit']\n",
    "\n",
    "#plot decision boundary\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8)\n",
    "\n",
    "X2 = df[[feature1, feature2]]\n",
    "X_scaler = StandardScaler()\n",
    "X2 = X_scaler.fit_transform(X2)\n",
    "X2 = pd.DataFrame(X2)\n",
    "\n",
    "Q = X2.values\n",
    "h = .02  # meshsize\n",
    "x_min, x_max = Q[:, 0].min() - .5, Q[:, 0].max() + .5 \n",
    "y_min, y_max = Q[:, 1].min() - .5, Q[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "model =  LogisticRegression()\n",
    "model.fit(X_train.iloc[:,:2],y_train)\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()]) # ravel() flattens the data\n",
    "\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(Q[:, 0], Q[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.title('Decision boundary using Log Regression')\n",
    "plt.xlabel(feature1)\n",
    "plt.ylabel(feature2)\n",
    "\n",
    "#plt.xlim(xx.min(), xx.max())\n",
    "#plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "#if bounds arent great specify them manually\n",
    "print(xx.min(), xx.max(), yy.min(), yy.max())\n",
    "plt.xlim(xx.min(), 5)\n",
    "plt.ylim(yy.min(), 3)\n",
    "plt.xticks(())\n",
    "plt.yticks(());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "8.We have not covered random forests but they are a very popular type of classifier. It is very good practice in reading the docs to get a new classifier working. Read [this](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and then apply the RandomForestClassifier()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'n_jobs': -1} RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=200, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "{'n_estimators': 400, 'n_jobs': -1} RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=400, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "{'n_estimators': 200, 'n_jobs': -1} RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=200, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "{'n_estimators': 400, 'n_jobs': -1} RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=400, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "{'n_estimators': 300, 'n_jobs': -1} RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=300, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "200\n",
      "best classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       763\n",
      "          1       1.00      1.00      1.00       585\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1348\n",
      "\n",
      "av_roc_auc 0.968842788551\n",
      "av_acc_test 0.918397626113\n",
      "av_precision 0.901155617764\n",
      "av_recall 0.910402528435\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEWCAYAAADy2YssAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119ee3668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#first find best parameters for RandomForest before using pipeline\n",
    "def best_params(X,y):\n",
    "    kf = KFold(n_splits=5, shuffle = True)\n",
    "    kf.get_n_splits(X)\n",
    "\n",
    "    n_estimators = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "    \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        param_grid = {'n_estimators': [100, 200, 300, 400], 'n_jobs': [-1]}\n",
    "\n",
    "        grid = GridSearchCV(RandomForestClassifier(), \n",
    "                    param_grid, \n",
    "                    cv=3, \n",
    "                    scoring='accuracy')\n",
    "\n",
    "        grid = grid.fit(X_train, y_train)\n",
    "\n",
    "        print(grid.best_params_, grid.best_estimator_)\n",
    "        n_estimators.append(grid.best_params_['n_estimators'])\n",
    "        \n",
    "    return mode(n_estimators)[0][0]\n",
    "\n",
    "best_parameter = best_params(X,y)\n",
    "print(best_parameter)\n",
    "\n",
    "#now use pipeline\n",
    "acc_test, roc_score, precision, recall, _ =  my_classifier(X,y, 'randomforest',best_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.Support vector machines are another type of classifier. Read the docs [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) and then try implementing that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Take in a new school's data and predict the school's profit status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.What are the worst schools? Some of them are chains so don't necessarily consider singular names but generalize to chains. Give justification for your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.If you were a governmental organization overseeing accreditation, what factors would be most important to you in making sure that the college was non-predatory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert 12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
