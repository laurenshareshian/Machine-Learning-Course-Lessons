{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to import the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our example yesterday. We first used the Tfidf Vectorizer to preprocess the data and turn the words into a matrix where uncommon words were granted more weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseball</th>\n",
       "      <th>basketball</th>\n",
       "      <th>broncos</th>\n",
       "      <th>cowboys</th>\n",
       "      <th>cubs</th>\n",
       "      <th>football</th>\n",
       "      <th>giants</th>\n",
       "      <th>hendrix</th>\n",
       "      <th>jagger</th>\n",
       "      <th>jam</th>\n",
       "      <th>joplin</th>\n",
       "      <th>pearl</th>\n",
       "      <th>pop</th>\n",
       "      <th>prince</th>\n",
       "      <th>redsox</th>\n",
       "      <th>rock</th>\n",
       "      <th>stars</th>\n",
       "      <th>tigers</th>\n",
       "      <th>tupac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.479185</td>\n",
       "      <td>0.675356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.397106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.559675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.559675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.609819</td>\n",
       "      <td>0.609819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.479185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675356</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544082</td>\n",
       "      <td>0.451635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473977</td>\n",
       "      <td>0.570997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461804</td>\n",
       "      <td>0.461804</td>\n",
       "      <td>0.461804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseball  basketball   broncos   cowboys      cubs  football    giants  \\\n",
       "0  0.479185    0.675356  0.000000  0.000000  0.000000  0.560603  0.000000   \n",
       "1  0.397106    0.000000  0.000000  0.000000  0.559675  0.000000  0.559675   \n",
       "2  0.000000    0.000000  0.609819  0.609819  0.000000  0.506202  0.000000   \n",
       "3  0.479185    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "    hendrix    jagger       jam    joplin     pearl       pop    prince  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.451635  0.000000  0.000000  0.000000  0.000000  0.544082  0.451635   \n",
       "5  0.473977  0.570997  0.000000  0.000000  0.000000  0.000000  0.473977   \n",
       "6  0.000000  0.000000  0.461804  0.461804  0.461804  0.000000  0.000000   \n",
       "\n",
       "     redsox      rock     stars    tigers     tupac  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.464579  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.560603  0.000000  0.000000  0.675356  0.000000  \n",
       "4  0.000000  0.000000  0.544082  0.000000  0.000000  \n",
       "5  0.000000  0.473977  0.000000  0.000000  0.000000  \n",
       "6  0.000000  0.383337  0.000000  0.000000  0.461804  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = ['Football baseball basketball',\n",
    "            'baseball giants cubs redsox',\n",
    "            'football broncos cowboys',\n",
    "            'baseball redsox tigers',\n",
    "            'pop stars hendrix prince',\n",
    "            'hendrix prince jagger rock',\n",
    "            'joplin pearl jam tupac rock',\n",
    "          ]\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True, \n",
    "                     token_pattern=\"\\\\b[a-zA-Z][a-zA-Z]+\\\\b\", \n",
    "                     stop_words=stopwords.words('english'),\n",
    "                     min_df=1)\n",
    "\n",
    "X = vectorizer.fit_transform(articles).toarray()\n",
    "\n",
    "pd.DataFrame(X,\n",
    "             columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we used an SVD to view the most important words making up each component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseball</th>\n",
       "      <th>basketball</th>\n",
       "      <th>broncos</th>\n",
       "      <th>cowboys</th>\n",
       "      <th>cubs</th>\n",
       "      <th>football</th>\n",
       "      <th>giants</th>\n",
       "      <th>hendrix</th>\n",
       "      <th>jagger</th>\n",
       "      <th>jam</th>\n",
       "      <th>joplin</th>\n",
       "      <th>pearl</th>\n",
       "      <th>pop</th>\n",
       "      <th>prince</th>\n",
       "      <th>redsox</th>\n",
       "      <th>rock</th>\n",
       "      <th>stars</th>\n",
       "      <th>tigers</th>\n",
       "      <th>tupac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>component_1</th>\n",
       "      <td>0.59434</td>\n",
       "      <td>0.26389</td>\n",
       "      <td>0.10775</td>\n",
       "      <td>0.10775</td>\n",
       "      <td>0.25565</td>\n",
       "      <td>0.30849</td>\n",
       "      <td>0.25565</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.47627</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.31811</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_2</th>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.51977</td>\n",
       "      <td>0.33357</td>\n",
       "      <td>0.10539</td>\n",
       "      <td>0.10539</td>\n",
       "      <td>0.10539</td>\n",
       "      <td>0.29259</td>\n",
       "      <td>0.51977</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.36438</td>\n",
       "      <td>0.29259</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.10539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             baseball  basketball  broncos  cowboys     cubs  football  \\\n",
       "component_1   0.59434     0.26389  0.10775  0.10775  0.25565   0.30849   \n",
       "component_2  -0.00000     0.00000  0.00000  0.00000  0.00000   0.00000   \n",
       "\n",
       "              giants  hendrix   jagger      jam   joplin    pearl      pop  \\\n",
       "component_1  0.25565  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000   \n",
       "component_2  0.00000  0.51977  0.33357  0.10539  0.10539  0.10539  0.29259   \n",
       "\n",
       "              prince   redsox     rock    stars   tigers    tupac  \n",
       "component_1  0.00000  0.47627  0.00000  0.00000  0.31811  0.00000  \n",
       "component_2  0.51977 -0.00000  0.36438  0.29259 -0.00000  0.10539  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(2)\n",
    "X_svd = svd.fit_transform(X)\n",
    "pd.DataFrame(svd.components_.round(5),\n",
    "             index = [\"component_1\",\"component_2\"],\n",
    "             columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we also wanted to scale our data using Normalizer. This ensures that each vector has a \"norm\" of 1. Vectors with a norm of 1 are easy to work with for calculating similarity. We see that each document is a linear combination of the components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Football baseball basketball</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball giants cubs redsox</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>football broncos cowboys</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball redsox tigers</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop stars hendrix prince</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hendrix prince jagger rock</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joplin pearl jam tupac rock</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              component_1  component_2\n",
       "Football baseball basketball          1.0         -0.0\n",
       "baseball giants cubs redsox           1.0          0.0\n",
       "football broncos cowboys              1.0          0.0\n",
       "baseball redsox tigers                1.0         -0.0\n",
       "pop stars hendrix prince              0.0          1.0\n",
       "hendrix prince jagger rock            0.0          1.0\n",
       "joplin pearl jam tupac rock           0.0          1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_svd = Normalizer(copy=False).fit_transform(X_svd)\n",
    "\n",
    "pd.DataFrame(dtm_svd.round(5),\n",
    "             index=articles, \n",
    "             columns=[\"component_1\",\"component_2\" ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "\n",
    "We can create a pipeline that performs all of the above processes. Let's make the pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = [('tfidf', TfidfVectorizer(stop_words='english', \n",
    "                        token_pattern=\"\\\\b[a-zA-Z][a-zA-Z]+\\\\b\", \n",
    "                        min_df=2)),\n",
    "       ('lsa', TruncatedSVD(2)),\n",
    "       ('normalizer', Normalizer())]\n",
    "pipeline = Pipeline(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can put our article data through the pipe to generate the exact table that we made above. The code is a lot cleaner this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Football baseball basketball</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball giants cubs redsox</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>football broncos cowboys</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseball redsox tigers</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop stars hendrix prince</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hendrix prince jagger rock</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joplin pearl jam tupac rock</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              component_1  component_2\n",
       "Football baseball basketball          1.0          0.0\n",
       "baseball giants cubs redsox           1.0         -0.0\n",
       "football broncos cowboys              1.0          0.0\n",
       "baseball redsox tigers                1.0         -0.0\n",
       "pop stars hendrix prince             -0.0          1.0\n",
       "hendrix prince jagger rock           -0.0          1.0\n",
       "joplin pearl jam tupac rock          -0.0          1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_svd = pipeline.fit_transform(articles)\n",
    "pd.DataFrame(dtm_svd.round(5),\n",
    "             index=articles, \n",
    "             columns=[\"component_1\",\"component_2\" ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Topic Modeling\n",
    "\n",
    "When we chose two components to use in our SVD, we were essentially choosing to use two topics. We can view the five most important words associated with each topic below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Topic 1:                                    \n",
      "baseball redsox tigers football basketball\n",
      "--------------------------------------------------------------------------------\n",
      "                                    Topic 2:                                    \n",
      "prince hendrix rock jagger stars\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_topics = 2\n",
    "n_words = 5\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "for topic_num in range(n_topics):\n",
    "    topic_mat = svd.components_[topic_num]\n",
    "\n",
    "    print('Topic {}:'.format(topic_num + 1).center(80))\n",
    "\n",
    "    topic_values = sorted(zip(topic_mat, feature_names), \n",
    "                          reverse=True)[:n_words]\n",
    "    print(' '.join([y for x,y in topic_values]))\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Predictive Modeling\n",
    "\n",
    "Here we will train a model on our outcome (Sports 1 or Music 0) and then use the model to predict on new sentences what we are talking about. First, let's add a logistic regression classifier to the end of our pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "pipeline = Pipeline(pipe + [('est', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use our previous articles as our training data and predict a topic with a test sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76068417]\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(articles, [1,1,1,1,0,0,0])\n",
    "\n",
    "new_sentence = 'babe ruth played baseball'\n",
    "y_pred_1 = pipeline.predict_proba([new_sentence])[:, 1]\n",
    "print(y_pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, it makes sense that this new article was labeled as sports instead of music. What about a new sentence about music?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31908412]\n"
     ]
    }
   ],
   "source": [
    "new_sentence = 'rock and roll music'\n",
    "y_pred_1 = pipeline.predict_proba([new_sentence])[:, 1]\n",
    "print(y_pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would get labeled as music."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Article Suggestions\n",
    "\n",
    "We can use a similar function to the one we used in our recommendation system unit to find articles most similar to a given article. Let's find the sentence most similar to Sentence 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article #3: baseball redsox tigers. Similarity score: 1.0.\n",
      "Article #2: football broncos cowboys. Similarity score: 1.0.\n",
      "Article #1: baseball giants cubs redsox. Similarity score: 1.0.\n",
      "Article #5: hendrix prince jagger rock. Similarity score: 3.1899559897031195e-15.\n",
      "Article #4: pop stars hendrix prince. Similarity score: 3.1428748374072194e-15.\n"
     ]
    }
   ],
   "source": [
    "def get_article_recommendations(articles, compare_article, df, num_recom):\n",
    "    recs = []\n",
    "    for article in range(len(df)):\n",
    "        if article != compare_article:\n",
    "            recs.append((np.dot(df[compare_article],df[article]), article))\n",
    "            recs.sort(reverse = True)\n",
    "    for i in range(num_recom):\n",
    "        print(f\"Article #{recs[i][1]}: {articles[recs[i][1]]}. Similarity score: {recs[i][0]}.\")\n",
    "\n",
    "article_num = 0\n",
    "get_article_recommendations(articles, article_num,dtm_svd,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense that Sentences 3, 2, and 1 are most similar to Sentence 0, as they are all sports-related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Sentiment Analysis\n",
    "\n",
    "Natural language processing can handle sentiment analysis. Polarity is near +1 for highly positive sentiment and near -1 for highly negative sentiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a highly positive sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.302, 'pos': 0.698, 'compound': 0.9107}\n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "print(sid.polarity_scores(\"Oh my god I love football, it's so awesome.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a highly negative sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.598, 'neu': 0.402, 'pos': 0.0, 'compound': -0.8147}\n"
     ]
    }
   ],
   "source": [
    "print(sid.polarity_scores(\"I hate swimming it makes me so tired.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
