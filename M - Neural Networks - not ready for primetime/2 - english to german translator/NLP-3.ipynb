{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New Translator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a6PKIJC404Q",
        "colab_type": "text"
      },
      "source": [
        "Copied from this source:\n",
        "https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html and Sophie's tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J21oThYy2rmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "SRC = Field(tokenize = \"spacy\",\n",
        "            # tokenizer_language=\"de\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "\n",
        "TRG = Field(tokenize = \"spacy\",\n",
        "            # tokenizer_language=\"en\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vh50Zx0hHLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),\n",
        "                                                    fields = (SRC, TRG))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZPNYXh3hMrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZAYT0cShYBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk28lwshhaEa",
        "colab_type": "code",
        "outputId": "6b8229b7-c9af-4485-d02d-ac9e87f6af90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 attn_dim: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "\n",
        "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "\n",
        "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "\n",
        "    def forward(self,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((\n",
        "            repeated_decoder_hidden,\n",
        "            encoder_outputs),\n",
        "            dim = 2)))\n",
        "\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 output_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: int,\n",
        "                 attention: nn.Module):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "\n",
        "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def _weighted_encoder_rep(self,\n",
        "                              decoder_hidden: Tensor,\n",
        "                              encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        a = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "\n",
        "        return weighted_encoder_rep\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                input: Tensor,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                          encoder_outputs)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "\n",
        "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "\n",
        "        output = self.out(torch.cat((output,\n",
        "                                     weighted_encoder_rep,\n",
        "                                     embedded), dim = 1))\n",
        "\n",
        "        return output, decoder_hidden.squeeze(0)\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: nn.Module,\n",
        "                 decoder: nn.Module,\n",
        "                 device: torch.device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                teacher_forcing_ratio: float = 0.5) -> Tensor:\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        # first input to the decoder is the <sos> token\n",
        "        output = trg[0,:]\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "# ENC_EMB_DIM = 256\n",
        "# DEC_EMB_DIM = 256\n",
        "# ENC_HID_DIM = 512\n",
        "# DEC_HID_DIM = 512\n",
        "# ATTN_DIM = 64\n",
        "# ENC_DROPOUT = 0.5\n",
        "# DEC_DROPOUT = 0.5\n",
        "\n",
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "ENC_HID_DIM = 64\n",
        "DEC_HID_DIM = 64\n",
        "ATTN_DIM = 8\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "\n",
        "def init_weights(m: nn.Module):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,857,261 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79GdEY2ghfss",
        "colab_type": "code",
        "outputId": "db87c191-379d-4c16-dc49-fe9b09c39dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "print(PAD_IDX)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHbmjpcK5ZDf",
        "colab_type": "text"
      },
      "source": [
        "*** Start reading new stuff here***\n",
        "To speed up process, I am only running one epoch currently. Change it back to at least 10 when you are done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzBhkzZb5YO3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c695a3af-646c-4f1d-afe8-58a91f8276d0"
      },
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          iterator: BucketIterator,\n",
        "          optimizer: optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          clip: float):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for _, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module,\n",
        "             iterator: BucketIterator,\n",
        "             criterion: nn.Module):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 1\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 29s\n",
            "\tTrain Loss: 5.682 | Train PPL: 293.448\n",
            "\t Val. Loss: 5.251 |  Val. PPL: 190.777\n",
            "| Test Loss: 5.259 | Test PPL: 192.284 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qYGsD0j5lv1",
        "colab_type": "text"
      },
      "source": [
        "How could you use this model to predict a new value? I think like this?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fcr75xX51Jt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5487cdde-5fa6-462d-8a29-6228660792fe"
      },
      "source": [
        "x_test = next(enumerate(train_iterator))[1].src.to(device)\n",
        "y_test = torch.tensor([[0]]).to(device) #next(enumerate(train_iter))[1].src.to(device)  # i think maybe we can leave the target empty?\n",
        "result = model(x_test, y_test)\n",
        "print(result)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZWDKoAo5s1e",
        "colab_type": "text"
      },
      "source": [
        "How could we translate this back? Well, let's explore how to create examples from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-GiFiJ56HGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a3b4c7e-a5c5-415e-da37-091f958ae4e8"
      },
      "source": [
        "from torchtext.data import Example\n",
        "test = Example.fromlist(data=['zwei junge weiße männer sind i m freien in der nähe vieler büsche'], fields=[('src', SRC)])\n",
        "print(test.src)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['zwei', 'junge', 'weiße', 'männer', 'sind', 'i', 'm', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWY6LhJj6UIq",
        "colab_type": "text"
      },
      "source": [
        "Make this singular sentence into a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31VGORxD6XS3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05463abe-c1f8-4086-8edf-a7c6ace99c90"
      },
      "source": [
        "from torchtext.data import Dataset\n",
        "custom_test_data = Dataset([test], fields=[('src', SRC)])\n",
        "print(type(custom_test_data))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torchtext.data.dataset.Dataset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL01mjft646u",
        "colab_type": "text"
      },
      "source": [
        "And make a bucket. Then we'll be able to view the vector form of this sentence that we created from scratch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihYqaJ-U64KF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "8851a5f3-b1af-405b-cabf-4d6ec9138204"
      },
      "source": [
        " from torchtext.data import BucketIterator\n",
        " test_iter = BucketIterator(dataset=custom_test_data, batch_size=1)\n",
        " print(next(enumerate(test_iter))[1].src)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[   2],\n",
            "        [  18],\n",
            "        [  28],\n",
            "        [ 216],\n",
            "        [  32],\n",
            "        [  86],\n",
            "        [  20],\n",
            "        [  21],\n",
            "        [  90],\n",
            "        [   7],\n",
            "        [  15],\n",
            "        [ 116],\n",
            "        [7663],\n",
            "        [3219],\n",
            "        [   3]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGzFptMG6W12",
        "colab_type": "text"
      },
      "source": [
        "Then, we could apply the model to predict the english translation vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SISJ5wTZk-oP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa3a54c8-7754-4f76-cab0-74b83fe5e477"
      },
      "source": [
        "x_test = next(enumerate(test_iter))[1].src.to(device)\n",
        "y_test = torch.tensor([[0]]).to(device) #next(enumerate(test_iter))[1].src.to(device)  # I think we can keep this target empty...?\n",
        "result = model(x_test,y_test)\n",
        "print(result)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRQN8UgT7xG9",
        "colab_type": "text"
      },
      "source": [
        "How do we convert a tensor back to a sentence? Let's first define this helper function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU_gAG5MozFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_ids_to_sentence(id_tensor, vocab, join=None):\n",
        "    \"\"\"Converts a sequence of word ids to a sentence\"\"\"\n",
        "    if isinstance(id_tensor, torch.LongTensor):\n",
        "        ids = id_tensor.transpose(0, 1).contiguous().view(-1)\n",
        "    elif isinstance(id_tensor, np.ndarray):\n",
        "        ids = id_tensor.transpose().reshape(-1)\n",
        "    batch = [vocab.itos[ind] for ind in ids] # denumericalize\n",
        "    if join is None:\n",
        "        return batch\n",
        "    else:\n",
        "        return 'model translation: '+join.join(batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QiNmidB78Bl",
        "colab_type": "text"
      },
      "source": [
        "Applying this method doesn't give us an error but also doesn't give us something that makes sense, so we'll need to investigate further:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nis5dvTVpnm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fae7cb5e-b2f5-4603-a877-e50cf1d93195"
      },
      "source": [
        "import numpy as np\n",
        "print('x-test sample: ' 'zwei junge weiße männer sind i m freien in der nähe vieler büsche')\n",
        "print('correct translation: ', 'two young white men are outdoors near many bushes')\n",
        "arrs = model(x_test, y_test).cpu().data.numpy()\n",
        "word_ids_to_sentence(np.argmax(arrs, axis=2), TRG.vocab, join=' ')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x-test sample: zwei junge weiße männer sind i m freien in der nähe vieler büsche\n",
            "correct translation:  two young white men are outdoors near many bushes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model translation: <unk>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho0TQTA6wv19",
        "colab_type": "text"
      },
      "source": [
        "### We can correctly create an english sentence, convert it to a vector, and convert it back to an english sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxXaLhRArFXE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cab9838f-6e55-4842-8b1e-0b2c0ed46f44"
      },
      "source": [
        "print('original: ', 'a man in an orange hat starring at something.')\n",
        "train = Example.fromlist(\n",
        "    data=['a man in an orange hat starring at something.'], \n",
        "    fields=[('trg', TRG)])\n",
        "custom_train_data = Dataset([train], fields=[('trg', TRG)])\n",
        "train_iter = BucketIterator(\n",
        "    dataset=custom_train_data, batch_size=1)\n",
        "s = next(enumerate(train_iter))[1].trg.to(device)\n",
        "\n",
        "word_ids_to_sentence(s.cpu().data.numpy(), TRG.vocab, join=' ')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original:  a man in an orange hat starring at something.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model translation: <sos> a man in an orange hat starring at something . <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgM9B-lI8wwN",
        "colab_type": "text"
      },
      "source": [
        "### We can correctly create an german sentence, convert it to a vector, and convert it back to an german sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdlwUK5GsGMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5f928676-50f3-45b4-b43f-f80de23c1df0"
      },
      "source": [
        "print('original', 'ein Mann in einem orangefarbenen Hut mit einem Blick auf etwas.')\n",
        "train = Example.fromlist(\n",
        "    data=['ein Mann in einem orangefarbenen Hut mit einem Blick auf etwas.'], \n",
        "    fields=[('src', SRC)])\n",
        "custom_train_data = Dataset([train], fields=[('src', SRC)])\n",
        "train_iter = BucketIterator(\n",
        "    dataset=custom_train_data, batch_size=1)\n",
        "s = next(enumerate(train_iter))[1].src.to(device)\n",
        "\n",
        "word_ids_to_sentence(s.cpu().data.numpy(), SRC.vocab, join=' ')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original ein Mann in einem orangefarbenen Hut mit einem Blick auf etwas.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model translation: <sos> ein mann in einem orangefarbenen hut mit einem blick auf etwas . <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6qyp3_b83aI",
        "colab_type": "text"
      },
      "source": [
        "For some reason, though, I am having difficulty taking a german sentence from the actual training set and converting it to a vector and back to a proper translation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2xmox3Kw9Lh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6029a990-272e-4eb1-a7d9-efe6f967e9b6"
      },
      "source": [
        "data = ' '.join(train_data[0].src)\n",
        "print(data)\n",
        "train = Example.fromlist(\n",
        "    data=data, \n",
        "    fields=[('src', SRC)])\n",
        "custom_train_data = Dataset([train], fields=[('src', SRC)])\n",
        "train_iter = BucketIterator(\n",
        "    dataset=custom_train_data, batch_size=1)\n",
        "s = next(enumerate(train_iter))[1].src.to(device)\n",
        "\n",
        "word_ids_to_sentence(s.cpu().data.numpy(), SRC.vocab, join=' ')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "zwei junge weiße männer sind i m freien in der nähe vieler büsche .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model translation: <sos> <unk> <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6gPrXVp9MD8",
        "colab_type": "text"
      },
      "source": [
        "In addition, I am having difficulty taking an english sentence from the actual training set and converting it to a vector and back to a proper translation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFxiPuvbyJGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65b6ac71-753c-485e-ba48-f2383bdf6f0c"
      },
      "source": [
        "data = ' '.join(train_data[0].trg)\n",
        "print(data)\n",
        "train = Example.fromlist(\n",
        "    data=data, \n",
        "    fields=[('src', SRC)])\n",
        "custom_train_data = Dataset([train], fields=[('src', SRC)])\n",
        "train_iter = BucketIterator(\n",
        "    dataset=custom_train_data, batch_size=1)\n",
        "s = next(enumerate(train_iter))[1].src.to(device)\n",
        "\n",
        "word_ids_to_sentence(s.cpu().data.numpy(), SRC.vocab, join=' ')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "two young , white males are outside near many bushes .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model translation: <sos> t <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVPkw67A-Q0S",
        "colab_type": "text"
      },
      "source": [
        "Once you figure out the issue, I think you may be just about done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck2CShhf01AD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}